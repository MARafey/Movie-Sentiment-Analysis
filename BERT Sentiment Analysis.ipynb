{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:46:51.792298Z",
     "start_time": "2024-06-30T06:46:51.767871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ],
   "id": "c4feeddd63bf9972",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:46:53.326218Z",
     "start_time": "2024-06-30T06:46:51.794460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('archive/IMDB Dataset.csv')"
   ],
   "id": "4947249f6bf4443a",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:46:53.387472Z",
     "start_time": "2024-06-30T06:46:53.327621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode labels (assuming binary classification for sentiment analysis)\n",
    "df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0) # 1 for positive, 0 for negative"
   ],
   "id": "4617d7b6f2b3cc16",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:46:53.696086Z",
     "start_time": "2024-06-30T06:46:53.390469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2) # 80% training, 20% validation"
   ],
   "id": "da13d18ade7d0d5e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:46:54.540312Z",
     "start_time": "2024-06-30T06:46:53.701418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert pandas DataFrame to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_df) \n",
    "val_dataset = Dataset.from_pandas(val_df)   "
   ],
   "id": "501e4d19944ca1cf",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:46:55.646150Z",
     "start_time": "2024-06-30T06:46:54.543296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # Using the BERT tokenizer"
   ],
   "id": "640d409076cc246",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:46:55.676887Z",
     "start_time": "2024-06-30T06:46:55.650685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['review'], padding=\"max_length\", truncation=True) # Tokenize the reviews and pad them to the maximum length"
   ],
   "id": "df8c8322337ece55",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:51:53.045994Z",
     "start_time": "2024-06-30T06:46:55.680913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize the datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True) \n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ],
   "id": "e71114f85f341704",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44bc460718cf43d4b071b37868fd3785"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "848aa09bcad44484a48ceb56afa097a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:51:53.061544Z",
     "start_time": "2024-06-30T06:51:53.049008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the format of the datasets to PyTorch tensors (for the model)\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ],
   "id": "5232c81c6ab4b4d0",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:51:55.236798Z",
     "start_time": "2024-06-30T06:51:53.069084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2) # Binary classification"
   ],
   "id": "c7f5dde10703064e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:51:55.408591Z",
     "start_time": "2024-06-30T06:51:55.237816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # output directory\n",
    "    num_train_epochs=3, # total number of training epochs\n",
    "    per_device_train_batch_size=8, # batch size per device during training\n",
    "    per_device_eval_batch_size=8, # batch size for evaluation\n",
    "    warmup_steps=500, # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01, # strength of weight decay (L2 regularization) \n",
    "    logging_dir='./logs', # directory for storing logs\n",
    "    logging_steps=10, # log every 10 steps\n",
    "    evaluation_strategy=\"epoch\" # evaluate at the end of each epoch\n",
    ")"
   ],
   "id": "ed5339cd6ea6fe84",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Desktop\\PCN\\Seniment Analysis\\venv\\lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:51:55.424986Z",
     "start_time": "2024-06-30T06:51:55.411632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define compute_metrics function\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)  # Predicted labels\n",
    "    labels = p.label_ids # True labels\n",
    "    accuracy = accuracy_score(labels, preds) # Accuracy\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary') # Precision, Recall, F1 Score\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ],
   "id": "f750b6cae522ce5e",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T06:52:03.978889Z",
     "start_time": "2024-06-30T06:51:55.427890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics # Compute metrics\n",
    ")"
   ],
   "id": "c50971f276bd552e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T11:17:57.199313Z",
     "start_time": "2024-06-30T06:52:03.980931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "trainer.train() # This will take a while to run depending on the number of epochs and the size of the dataset "
   ],
   "id": "c29f90aac8d076c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15000/15000 4:25:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.335200</td>\n",
       "      <td>0.255632</td>\n",
       "      <td>0.927100</td>\n",
       "      <td>0.939437</td>\n",
       "      <td>0.914269</td>\n",
       "      <td>0.926682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.244981</td>\n",
       "      <td>0.937600</td>\n",
       "      <td>0.940355</td>\n",
       "      <td>0.935503</td>\n",
       "      <td>0.937923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.320947</td>\n",
       "      <td>0.938200</td>\n",
       "      <td>0.940251</td>\n",
       "      <td>0.936892</td>\n",
       "      <td>0.938569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15000, training_loss=0.2002308165420778, metrics={'train_runtime': 15952.456, 'train_samples_per_second': 7.522, 'train_steps_per_second': 0.94, 'total_flos': 3.15733266432e+16, 'train_loss': 0.2002308165420778, 'epoch': 3.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T11:23:22.002877Z",
     "start_time": "2024-06-30T11:17:57.213512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate() # Evaluate the model on the validation set   "
   ],
   "id": "b7fd89a715cfa2fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 05:24]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T11:23:22.034802Z",
     "start_time": "2024-06-30T11:23:22.004820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Validation Loss: {eval_results['eval_loss']}\")\n",
    "print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
    "print(f\"Validation Precision: {eval_results['eval_precision']}\")\n",
    "print(f\"Validation Recall: {eval_results['eval_recall']}\")\n",
    "print(f\"Validation F1 Score: {eval_results['eval_f1']}\")"
   ],
   "id": "6256632762172324",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3209468126296997\n",
      "Validation Accuracy: 0.9382\n",
      "Validation Precision: 0.9402509460266879\n",
      "Validation Recall: 0.9368922405239135\n",
      "Validation F1 Score: 0.9385685884691849\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T11:27:37.239659Z",
     "start_time": "2024-06-30T11:27:36.298939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Saving the model\n",
    "model_path = 'bert_sentiment_analysis_model'\n",
    "model.save_pretrained(model_path)"
   ],
   "id": "885c947d26938224",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2ce9abbf81d1129"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
