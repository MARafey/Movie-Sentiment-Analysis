{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing the necessary libraries"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:03.391987Z",
     "start_time": "2024-06-27T14:54:03.379399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load the data\n",
    "`Giving the path of the dataset to read the data from the file.\n",
    "This will open the csv file and the data will be stored in the sample_data list.`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:03.861411Z",
     "start_time": "2024-06-27T14:54:03.447753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = \"archive/IMDB Dataset.csv\"\n",
    "sample_data = []\n",
    "file = open(filename, encoding=\"utf8\")\n",
    "csv_reader = csv.reader(file)\n",
    "for row in csv_reader:\n",
    "    sample_data.append(row)\n",
    "file.close()"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Seperating the data into X and Y values\n",
    "`The data is stored in the sample_data list. The first element of the list is the column names.\n",
    "The first column is the review and the second column is the sentiment.`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:03.877196Z",
     "start_time": "2024-06-27T14:54:03.862415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_Values = []\n",
    "Y_Values = []"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:03.908615Z",
     "start_time": "2024-06-27T14:54:03.879230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1, len(sample_data)):\n",
    "    X_Values.append(sample_data[i][0])\n",
    "    Y_Values.append(sample_data[i][1])"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Converting the Y values to binary form\n",
    "`The Y values are in the form of positive and negative. We need to convert them to 0 and 1.`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:03.924276Z",
     "start_time": "2024-06-27T14:54:03.912145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert the Y_Values to 0 and 1\n",
    "for i in range(len(Y_Values)):\n",
    "    if Y_Values[i] == \"positive\":\n",
    "        Y_Values[i] = 1\n",
    "    else:\n",
    "        Y_Values[i] = 0"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Converting the X and Y values to numpy arrays\n",
    "`The X and Y values are in the form of lists. We need to convert them to numpy arrays.`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:04.610921Z",
     "start_time": "2024-06-27T14:54:03.926183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert both arrays to numpy arrays\n",
    "X_Values = np.array(X_Values)\n",
    "Y_Values = np.array(Y_Values)"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing\n",
    "`The data is in the form of text and has been scrapped so it may contain unwanted html tags, special characters, etc.\n",
    "So, we need to preprocess the data before feeding it to the model.`\n",
    "\n",
    "1.  Using a Regrex to remove the unwanted characters by replacing them with a space. Each HTML tag contains a '<' and a '>'. So, we can remove them by replacing them with a space.\n",
    "2. We can also remove the special characters by replacing them with a space.\n",
    "3. We can also convert the text to lowercase.\n",
    "4. We can also remove the extra spaces."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:33.361458Z",
     "start_time": "2024-06-27T14:54:04.614903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing the unwanted Tags.\n",
    "X_Values = np.array([re.sub('<.*?>', ' ', data) for data in X_Values])\n",
    "# Removing the special characters.\n",
    "X_Values = np.array([re.sub('[^a-zA-Z0-9\\s]', ' ', data) for data in X_Values])\n",
    "# Converting the text to lowercase.\n",
    "X_Values = np.array([data.lower() for data in X_Values])\n",
    "# Removing the extra spaces.\n",
    "X_Values = np.array([' '.join(data.split()) for data in X_Values])\n",
    "# applying lemmatization\n",
    "X_Values = np.array([lemmatizer.lemmatize(data) for data in X_Values])\n",
    "#Removing stopwords\n",
    "X_Values = np.array([data for data in X_Values if data not in stop_words])"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:33.377030Z",
     "start_time": "2024-06-27T14:54:33.363347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Printing the first 5 X values.\n",
    "for i in range(5):\n",
    "    print(X_Values[i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the other reviewers has mentioned that after watching just 1 oz episode you ll be hooked they are right as this is exactly what happened with me the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the word it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to many aryans muslims gangstas latinos christians italians irish and more so scuffles death stares dodgy dealings and shady agreements are never far away i would say the main appeal of the show is due to the fact that it goes where other shows wouldn t dare forget pretty pictures painted for mainstream audiences forget charm forget romance oz doesn t mess around the first episode i ever saw struck me as so nasty it was surreal i couldn t say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards who ll be sold out for a nickel inmates who ll kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewing thats if you can get in touch with your darker side\n",
      "a wonderful little production the filming technique is very unassuming very old time bbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great master s of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwell s murals decorating every surface are terribly well done\n",
      "i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a light hearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to love this was the most i d laughed at one of woody s comedies in years dare i say a decade while i ve never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young woman this may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends\n",
      "basically there s a family where a little boy jake thinks there s a zombie in his closet his parents are fighting all the time this movie is slower than a soap opera and suddenly jake decides to become rambo and kill the zombie ok first of all when you re going to make a film you must decide if its a thriller or a drama as a drama the movie is watchable parents are divorcing arguing like in real life and then we have jake with his closet which totally ruins all the film i expected to see a boogeyman similar movie and instead i watched a drama with some meaningless thriller spots 3 out of 10 just for the well playing parents descent dialogs as for the shots with jake just ignore them\n",
      "petter mattei s love in the time of money is a visually stunning film to watch mr mattei offers us a vivid portrait about human relations this is a movie that seems to be telling us what money power and success do to people in the different situations we encounter this being a variation on the arthur schnitzler s play about the same theme the director transfers the action to the present time new york where all these different characters meet and connect each one is connected in one way or another to the next person but no one seems to know the previous point of contact stylishly the film has a sophisticated luxurious look we are taken to see how these people live and the world they live in their own habitat the only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits a big city is not exactly the best place in which human relations find sincere fulfillment as one discerns is the case with most of the people we encounter the acting is good under mr mattei s direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier and the rest of the talented cast make these characters come alive we wish mr mattei good luck and await anxiously for his next work\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:33.472595Z",
     "start_time": "2024-06-27T14:54:33.378634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Storing the Pure text data in a variable.\n",
    "Pure_text = X_Values"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Training\n",
    "1. Logistic Regression\n",
    "2. SVM\n",
    "3. Naive Bayes"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:33.487847Z",
     "start_time": "2024-06-27T14:54:33.474484Z"
    }
   },
   "cell_type": "code",
   "source": "model_scores = {}",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:34.453612Z",
     "start_time": "2024-06-27T14:54:33.489374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Splitting the data into training and testing data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Values, Y_Values, test_size=0.2, random_state=0)"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:55.305696Z",
     "start_time": "2024-06-27T14:54:34.455504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using CountVectorizer to convert the text data into numerical data.\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Using Logistic Regression to train the model.\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Logistic Regression Model Score: \", model.score(X_test, y_test))\n",
    "model_scores[\"Logistic Regression\"] = model.score(X_test, y_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Score:  0.8854\n",
      "Accuracy:  0.8854\n",
      "Precision:  0.8815184815184816\n",
      "Recall:  0.8886203423967775\n",
      "F1 Score:  0.8850551654964894\n",
      "Confusion Matrix:  [[4442  593]\n",
      " [ 553 4412]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Desktop\\PCN\\Seniment Analysis\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T14:54:55.399545Z",
     "start_time": "2024-06-27T14:54:55.308686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using Naive Bayes to train the model.\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Naive Bayes Model Score: \", model.score(X_test, y_test))\n",
    "model_scores[\"Naive Bayes\"] = model.score(X_test, y_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Score:  0.8436\n",
      "Accuracy:  0.8436\n",
      "Precision:  0.8667241751132198\n",
      "Recall:  0.8094662638469285\n",
      "F1 Score:  0.8371172672359926\n",
      "Confusion Matrix:  [[4417  618]\n",
      " [ 946 4019]]\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-27T14:54:55.401074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using SVM to train the model.\n",
    "# model = SVC()\n",
    "# running for 10 epoch\n",
    "model = SVC(kernel='linear', C=1, random_state=0, max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"SVM Model Score: \", model.score(X_test, y_test))\n",
    "model_scores[\"SVM\"] = model.score(X_test, y_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting Graph of the model scores"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Plotting the graph of the model scores.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(model_scores.keys(), model_scores.values())\n",
    "plt.ylabel(\"Model Scores\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.title(\"Model Scores of different models\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
